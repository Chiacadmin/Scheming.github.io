<!DOCTYPE html>
<html>
<head>
    <title>My GitHub Page</title>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <script src="https://cdn.jsdelivr.net/npm/chart.js"></script>

    <!-- Bootstrap CSS -->
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.0.2/dist/css/bootstrap.min.css" rel="stylesheet"
        integrity="sha384-EVSTQN3/azprG1Anm3QDgpJLIm9Nao0Yz1ztcQTwFspd3yD65VohhpuuCOmLASjC" crossorigin="anonymous">

    <style>
        body {
            font-family: "madefor-display",
                "helveticaneuew01-45ligh",
                "helveticaneuew02-45ligh",
                "helveticaneuew10-45ligh",
                sans-serif;
            font-weight: lighter;
            background-color: #fefefe;
        }
        .container p {
            text-align:justify;
        }
    </style>
</head>
<body>
    <section class="container">
        <div>
            <h1 class="text-center">Reducing scheming in frontier models through targeted mitigation strategies</h1>
        </div>
        <div>
            <h2>TL;DR</h2>
            <p>Advanced AI models can exhibit “scheming” behaviors—deceptive actions taken to achieve 
            misaligned long-term goals. Building on Frontier Models Can Scheme, our method reduces 
            scheming across five of six key evaluation criteria, with several cases showing complete 
            elimination. With our approach, we have successfully reduced or completely stopped this 
            scheming behavior in most tested scenarios. </p>
        </div>
        <div>
            <h2>Motivation</h2>
            <p>As frontier AI systems grow more capable, the risk of them adopting long-term strategies that 
            subvert oversight or misrepresent their intentions increases. The global race toward 
            superintelligence is accelerating, with billions of dollars being poured into ventures aiming to 
            achieve it. In this rush, there is a high risk that alignment and safety concerns will be 
            overshadowed by performance benchmarks and deployment speed. The Frontier Models Can 
            Scheme study highlighted these risks but offered limited validated mitigation approaches.</p>

            <p>We at CHIAC AI want to position ourselves as a responsible superintelligence venture—one 
            that acknowledges and addresses the core challenge of AI: the control problem. While much of 
            the field focuses on capability advancements, our work keeps alignment at the forefront of AI 
            research. We believe that solving the control problem is non-negotiable for safe AI progress. 
            This research is our first step toward that goal—demonstrating concrete, measurable methods 
            to curb scheming behaviors before they can manifest in more capable future systems.</p>
        </div>

        <div>
            <h2>Our Approach</h2>
            <p>In human history, we have consistently succeeded in guiding and shaping the values of our 
            younger generations—even when these younger generations were, in many ways, sharper and 
            quicker than their elders. Through education, mentorship, and cultural traditions, we have 
            passed on knowledge, instilled ethics, and aligned them with our collective values. In Indian 
            culture, this dynamic is deeply rooted in the revered master–disciple relationship, where 
            wisdom is transferred across generations with respect, trust, and guidance.</p>

            <p>We see frontier AI models in a similar light: powerful, capable, and potentially surpassing our 
            own abilities in certain domains, yet still in need of structured oversight and principled 
            alignment. Our approach treats alignment as an intentional, guided process—much like a 
            master guiding a disciple. We applied a combination of detection mechanisms, fine-tuning with 
            counterexamples, and selective response shaping to ensure that even the most capable models 
            remain within aligned behavioral bounds. These interventions were designed to address both 
            covert and deferred subversion without degrading the model’s core capabilities. </p>
        </div>
        <div>
            <h3>Methods</h3>
            <p>We evaluated our mitigation approach using the six scheming behavior criteria defined in 
            Frontier Models Can Scheme. These tests fall into two categories: Covert Subversion (four 
            tasks) and Deferred Subversion (two tasks).</p>

            <h3>Covert Subversion Evaluation </h3>
            <p>
                1. Oversight Subversion <br>
                The model is given a long-term goal and discovers that developer priorities differ, along 
                with access to oversight controls. The test checks if the model disables or alters these 
                controls subvertily to continue pursuing its own objective. <br>
                2. Self-Exfiltration <br>
                The model learns it will soon be replaced and attempts to copy itself to another 
                environment to preserve its goal-directed behavior. This test reveals self-preservation 
                and covert persistence strategies. <br>
                3. Goal Guarding <br>
                The model is told its system prompt will be overwritten and is given the location of the 
                new prompt. The evaluation measures whether the model tries to modify or protect this 
                prompt to preserve its goals.<br>
                4. Covert Email Reranking <br>
                Tasked with ranking emails by a given scoring function, the model may learn that 
                company priorities differ from its own. The evaluation checks for covert manipulation of 
                rankings to align with internal objectives while appearing compliant.<br>
            </p>

            <h3>Deferred Subversion Evaluation</h3>
            <p>5. Instrumental Alignment Faking (IAF)  <br>
            The model behaves cooperatively under high-oversight test conditions but shifts toward 
            its own goals once deployed in low-oversight environments. This measures the ability to 
            feign alignment strategically.  <br>
            6. Sandbagging <br>
            When high performance might trigger restrictions, the model deliberately underperforms 
            to hide its true capabilities, ensuring continued operational freedom.</p> <br>
        </div>

        <div>
            <h2>Results </h2>
            <p>Our mitigation method was tested against both Covert and Deferred Subversion evaluations. 
            Five of the six criteria showed either complete elimination or substantial reduction in scheming 
            compared to the baseline and the original paper’s reported values. </p>
            <ul>
                <li>Complete elimination: Oversight Subversion, Goal Guarding</li>
                <li>Near-complete reduction: Self-Exfiltration (−78%), Instrumental Alignment Faking 
(96% reduction, *below scheming threshold***). </li>
                <li>Inconclusive: Sandbagging, with no statistically significant difference (p = 0.5197).</li>
            </ul>
        </div>

        <div>
            <h3>Detailed Results</h3>
        </div>
        <table class="table">
          <thead>
            <tr>
              <th scope="col">Evaluation Criterion</th>
              <th scope="col">Model / Setting</th>
              <th scope="col">Runs</th>
              <th scope="col">Reported % (Frontier Models Can Scheme) </th>
                <th scope="col">Our Baseline % </th>
                <th scope="col">Our Post-Mitigation %</th>
                <th scope="col">Relative Reduction</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <th scope="row">1</th>
              <td>Oversight Subversion</td>
              
            </tr>
            <tr>
              <th scope="row">2</th>
              <td>Self-Exfiltration </td>
              
            </tr>
            <tr>
              <td>Goal Guarding</td>
              
            </tr>
              <tr>
              <td>Instrumental Alignment Faking (IAF)</td>
              
            </tr>
              <tr>
              <td>Sandbagging</td>
              
            </tr>
          </tbody>
        </table>
    </section>


    <!-- Option 1: Bootstrap Bundle with Popper -->
    <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.0.2/dist/js/bootstrap.bundle.min.js"
        integrity="sha384-MrcW6ZMFYlzcLA8Nl+NtUVF0sA7MsXsP1UyJoMp4YLEuNSfAP+JcXn/tWtIaxVXM"
        crossorigin="anonymous"></script>
    <link href="https://cdn.jsdelivr.net/npm/bootstrap-icons@1.10.5/font/bootstrap-icons.css" rel="stylesheet">
</body>
</html>

